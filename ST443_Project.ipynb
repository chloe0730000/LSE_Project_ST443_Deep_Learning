{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Kaggle sample:\n",
    "https://www.kaggle.com/kakauandme/tensorflow-deep-nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import tensorflow as tf   # pip install tensorflow  \n",
    "\n",
    "# settings\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# set to 20000 on local environment to get 0.99 accuracy\n",
    "TRAINING_ITERATIONS = 2500        \n",
    "    \n",
    "DROPOUT = 0.5\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "# set to 0 to train on all available data\n",
    "VALIDATION_SIZE = 2000\n",
    "\n",
    "# image number to output\n",
    "IMAGE_TO_DISPLAY = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "#path=\"/Users/chloe/Desktop/ST445_Project\"\n",
    "path='/Users/lin/Desktop/ST443_Project' # another laptop\n",
    "os.chdir(path)\n",
    "data = pd.read_csv('train.csv', sep=',') \n",
    "#test = pd.read_csv('test.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data(42000,785)\n"
     ]
    }
   ],
   "source": [
    "print('data({0[0]},{0[1]})'.format(data.shape)) # (42000, 785) -> include one label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "(42000, 784)\n"
     ]
    }
   ],
   "source": [
    "images = data.iloc[:,1:].values # all row, and from second col to last -> skip label in zero column\n",
    "print(images.dtype)\n",
    "images = images.astype(np.float)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "image_width => 28\n",
      "image_height => 28\n"
     ]
    }
   ],
   "source": [
    "image_size = images.shape[1] #784 variables\n",
    "print(image_size)\n",
    "\n",
    "# in this case all images are square\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "print ('image_width => {0}\\nimage_height => {1}'.format(image_width,image_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181e99cba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display image\n",
    "def display(img):\n",
    "    \n",
    "    # (784) => (28,28)\n",
    "    one_image = img.reshape(image_width,image_height)\n",
    "    \n",
    "    plt.axis('off') #remove axis\n",
    "    plt.imshow(one_image, cmap=cm.binary) #cmap=cm.binary -> display black/white image\n",
    "\n",
    "# output image     \n",
    "display(images[IMAGE_TO_DISPLAY])\n",
    "display(images[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_flat(42000)\n",
      "labels_count => 10\n"
     ]
    }
   ],
   "source": [
    "labels_flat = data[['label']].values.ravel() # make it array\n",
    "print('labels_flat({0})'.format(len(labels_flat)))\n",
    "\n",
    "labels_count = np.unique(labels_flat).shape[0] # have 10 numbers in the label: 0-9\n",
    "print('labels_count => {0}'.format(labels_count)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert labels from scalars to one-hot vectors\n",
    "\n",
    "* A one-hot vector is a vector that contains a single element equal to 1 and the rest of the elements equal to 0. <br\\> \n",
    "Ex: 0 => [1 0 0 0 0 0 0 0 0 0] <br\\>\n",
    "    1 => [0 1 0 0 0 0 0 0 0 0] <br\\>\n",
    "    ...                        <br\\>\n",
    "    9 => [0 0 0 0 0 0 0 0 0 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels(42000,10)\n",
      "labels[10] => [0 0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# convert class labels from scalars to one-hot vectors\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes # arange -> create array\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "labels = dense_to_one_hot(labels_flat, labels_count)\n",
    "labels = labels.astype(np.uint8)\n",
    "\n",
    "print('labels({0[0]},{0[1]})'.format(labels.shape))\n",
    "print ('labels[{0}] => {1}'.format(IMAGE_TO_DISPLAY,labels[IMAGE_TO_DISPLAY]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images(40000,784)\n",
      "validation_images(2000,784)\n"
     ]
    }
   ],
   "source": [
    "# split data into training & validation\n",
    "validation_images = images[:VALIDATION_SIZE] # we select 0:2000 as test; we set validation size=2000 (VALIDATION_SIZE = 2000)\n",
    "validation_labels = labels[:VALIDATION_SIZE]\n",
    "\n",
    "train_images = images[VALIDATION_SIZE:] # we select 2000-42000 as train\n",
    "train_labels = labels[VALIDATION_SIZE:]\n",
    "\n",
    "\n",
    "print('train_images({0[0]},{0[1]})'.format(train_images.shape))\n",
    "print('validation_images({0[0]},{0[1]})'.format(validation_images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Neural Nework Structure\n",
    "---\n",
    "Neural Network Process: <br/>\n",
    "image -> convolution -> max pooling -> convolution -> max pooling -> fully connected -> fully connected -> classifier\n",
    "\n",
    "---\n",
    "Ref:\n",
    "* https://brohrer.mcknote.com/zh-Hant/how_machine_learning_works/how_convolutional_neural_networks_work.html\n",
    "* http://cs231n.github.io/\n",
    "* https://www.youtube.com/watch?v=tjcgL5RIdTM&list=PLXO45tsB95cKI5AIlf5TxxFPzb-0zeVZ8&index=26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Things should notice for Weight initialization:\n",
    "\n",
    "Note that we do not know what the final value of every weight should be in the trained network, but with proper data normalization it is reasonable to assume that approximately half of the weights will be positive and half of them will be negative. \n",
    "A reasonable-sounding idea then might be to set all the initial weights to zero, which we expect to be the “best guess” in expectation. This turns out to be a mistake, because if every neuron in the network computes the same output, then they will also all compute the same gradients during backpropagation and undergo the exact same parameter updates. In other words, there is no source of asymmetry between neurons if their weights are initialized to be the same.\n",
    "Therefore, **we still want the weights to be very close to zero, but as we have argued above, not identically zero. As a solution, it is common to initialize the weights of the neurons to small numbers and refer to doing so as symmetry breaking.**\n",
    "\n",
    "* what is weight: http://cs231n.github.io/neural-networks-1/#nn\n",
    "* concept of weight and bias: y=ax+b (a: weight; b: bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weight initialization\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1) # create normal distribution\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convolution: https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/5-04-CNN2/\n",
    "def conv2d(x, W):\n",
    "    # x: all inputs; W: weight\n",
    "    # strides[1,x_movement,y_movement,1]: the output is the same size as the input\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pooling : extract the maximum value\n",
    "# [[0,3],[4,2]] => 4\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    # strides=[1,2,2,1] -> make 2(1+1_xmovement)*2(1+1_ymovement) into 1*1 -> squize the image \n",
    "    # ksize: extract info from 2*2 \n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input & output of NN\n",
    "\n",
    "# images\n",
    "x = tf.placeholder('float', shape=[None, image_size]) #image_siae=784 (28*28)\n",
    "# labels\n",
    "y_ = tf.placeholder('float', shape=[None, labels_count])\n",
    "\n",
    "# change the shape of x (784 -> 28*28)\n",
    "image = tf.reshape(x, [-1,image_width , image_height,1]) # -1: n_sample 1: our display image is in black/white "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conv1 layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32]) # patch:5*5; in size:1; out size:32\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(image, W_conv1) + b_conv1) # hidden layer convl; tf.nn.relu: make it non-linear \n",
    "# outpt size of h_convl will be 28*28*32\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "# output size of h_pool will be 14*14*32\n",
    "\n",
    "# conv2 layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64]) #patch:5*5; in size(width):32; out size(height):64\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # hidden layer convl; tf.nn.relu: make it non-linear \n",
    "# outpt size of h_convl will be 14*14*64\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "# output size of h_pool will be 7*7*64\n",
    "\n",
    "# func1 layer: hidden layer\n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64]) # [n_sample, 7,7,64] -> [n_sample, 7*7*64]\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "keep_prob = tf.placeholder('float')\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) # dropout: avoid overfit, apply this b4 readout layer\n",
    "\n",
    "\n",
    "# func2 layer: hidden layer (output layer輸出層)\n",
    "W_fc2 = weight_variable([1024, labels_count]) #labels_count: contains 0-9\n",
    "b_fc2 = bias_variable([labels_count])\n",
    "y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2) # use softmax to calculate probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost function\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "\n",
    "# optimisation function\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "\n",
    "# evaluation\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction function\n",
    "#[0.1, 0.9, 0.2, 0.1, 0.1 0.3, 0.5, 0.1, 0.2, 0.3] => 1\n",
    "predict = tf.argmax(y,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
